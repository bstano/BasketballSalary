---
title: "Basketball Salary"
author: "Ben Stano, ADD NAMES"
date: "2/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Baseketballs Brooooo

```{r, message=FALSE}
library(tidyverse)
```

## Importing Data

```{r}
# players <- read_csv("../data/players.csv")
# stats.36 <- read_csv("../data/PlayerStatisticsPer36Min.csv")
# stats.100 <- read_csv("../data/PlayerStatisticsPer100Poss.csv")
# stats.g <- read_csv("../data/PlayerStatisticsPerGame.csv")
# # salary <- read_csv("../data/salaries_1985to2018.csv")
# salary2 <- read_csv("../data/nba-salaries.csv")
```

## Cleaning and Merging Data

```{r}
# stats.g <- stats.g %>%
#   mutate(name = str_replace(Player, "\\*", ""))
# stats.g <- stats.g %>%
#   mutate(key = str_c(name, as.character(year), sep = ""))
# salary2 <- salary2 %>%
#   mutate(key = str_c(name, as.character(season), sep = ""))
```

### Joining the Datasets

```{r}
# final.data <- players %>%
#   inner_join(salary2, by = "name") %>%
#   inner_join(stats.g, by = "key") %>%
#   select(-key) %>%
#   filter(year >= 2017)
# 
# write_csv(final.data, "../data/final_data.csv")

bdata.raw <- read_csv("../data/final_data.csv")
```

### Cleaning the Data

```{r}
bdata.raw <- read_csv("../data/final_data.csv")
# displaying null values in each column
bdata.raw %>%
  map_dbl(~sum(is.na(.))) %>%
  unname() ->
na.dbl

na.cols <- data.frame("variable" = colnames(bdata.raw),
                      "null.count" = na.dbl)

na.cols %>%
  filter(null.count > 0)

# parsing numbers from difficult columns
bdata.raw$career_FG3_P <- parse_number(as.character(bdata.raw$`career_FG3%`))
bdata.raw$career_FG_P <- parse_number(as.character(bdata.raw$`career_FG%`))
bdata.raw$career_FT_P <- parse_number(as.character(bdata.raw$`career_FT%`))
# cleaning height
heights <- str_split(bdata.raw$height, "\\-")
heights.df <- t(data.frame(heights))
heights.int <- as.integer(heights.df[,1]) * 12 + as.integer(heights.df[,2])
bdata.raw$height <- heights.int

bdata.raw %>%
  mutate(draft_pick = parse_number(draft_pick),
         draft_round = parse_number(draft_round),
         shoots_right = ifelse(str_detect(shoots, "Right"),1,0),
         weight = parse_number(weight),
         Pos = as.factor(Pos)) %>%
  rename(career_eFG_P = `career_eFG%`,
         FG_P = `FG%`,
         THREEP_P = `3P%`,
         THREEP = `3P`,
         THREEP_A = `3PA`,
         TWOP_P = `2P%`,
         TWOP = `2P`,
         TWOP_A = `2PA`,
         eFG_P = `eFG%`,
         FT_P = `FT%`) %>%
  select(-birthDate, -birthPlace, -college, -draft_team, -highSchool, -name.x,
         -position.x, -position.y, -team, -Player, -name.y, -season, -Tm,
         -`career_FG3%`, -`career_FG%`, -`career_FT%`, -shoots) %>%
  na.omit() ->
bdata.clean

bdata.clean %>%
  select(-`_id`) ->
bdata.model
```


## Variables Names

 - **salary**: player salary 

## Dimensionality Reduction

```{r}
ols.init <- lm(salary ~ ., data = bdata.model)

summary(ols.init)

plot(ols.init, which = 1)

plot(ols.init, which = 2)
```

```{r, message=FALSE}
# library(klaR)
library(car)

# cond.index(ols.init, bdata.model)

vif(ols.init)
```

## Transforming the Respsonse Variable

```{r}
bdata.model %>%
  mutate(log_salary = log(salary)) -> 
bdata.log

bdata.log$salary <- NULL
```


```{r}
ols.log0 <- lm(log_salary ~ ., data = bdata.log)

summary(ols.log0)

plot(ols.log0, which = c(1, 2))

# cond.index(ols.log, bdata.log)

vif(ols.log0)
```
## Removing High Leverage Values (Outliers)

```{r}
bdata.log.rm <- bdata.log[-c(363, 774, 967), ]
```

```{r}
ols.log <- lm(log_salary ~ ., data = bdata.log.rm)

summary(ols.log)

plot(ols.log, which = c(1, 2))

# cond.index(ols.log, bdata.log)

vif(ols.log)
```

## Feature Selection

```{r}
vifs <- data.frame(vif(ols.log))

vifs %>%
  filter(GVIF > 1000) ->
vif.1000

drop.vars <- c(rownames(vif.1000))

bdata.log.rm %>%
  select(-drop.vars) ->
bdata.log2
```

### Refitting

```{r}
ols.log2 <- lm(log_salary ~ ., data = bdata.log2)

summary(ols.log2)

plot(ols.log2, which = c(1, 2))

vif(ols.log2)
```
```{r}
vifs2 <- data.frame(vif(ols.log2))

vifs2 %>%
  filter(GVIF > 50) ->
vif.50

drop.vars <- c(rownames(vif.50))

bdata.log2 %>%
  select(-drop.vars) ->
bdata.log3
```

### Refitting Again

```{r}
ols.log3 <- lm(log_salary ~ ., data = bdata.log3)

summary(ols.log3)

plot(ols.log3, which = c(1, 2))

vif(ols.log3)
```

```{r}
vifs3 <- data.frame(vif(ols.log3))

vifs3 %>%
  filter(GVIF > 20) ->
vif.20

drop.vars <- c(rownames(vif.20))

bdata.log3 %>%
  select(-drop.vars) ->
bdata.log4
```

### Refitting AGAIN AGAIN

```{r}
ols.log4 <- lm(log_salary ~ ., data = bdata.log4)

summary(ols.log4)

plot(ols.log4, which = c(1, 2))

vif(ols.log4)
```

```{r}
vifs4 <- data.frame(vif(ols.log4))

vifs4 %>%
  filter(`vif.ols.log4.` > 12) ->
vif.12

drop.vars <- c(rownames(vif.12))

bdata.log4 %>%
  select(-drop.vars) ->
bdata.log5

bdata.vif <- bdata.log5
```

### Final Fitting

```{r}
ols.log5 <- lm(log_salary ~ ., data = bdata.vif)

summary(ols.log5)

plot(ols.log5, which = c(1, 2))

vif(ols.log5)
```


## Feature Selection Use Stepwise Function

```{r}
fit.large <- lm(log_salary ~ ., data = bdata.log.rm)

fit.small <- lm(log_salary ~ 1, data = bdata.log.rm)

fit.step <- step(fit.large, fit.small)
```

### Two Feature Sets

```{r}
vars.vif <- names(vif(ols.log5))
bdata.vif <- bdata.log5

vars.step <- names(fit.step$coefficients)[-1]
bdata.log %>%
  select(c(vars.step, log_salary)) ->
bdata.step
```

## Validating Between the Two Feature Sets

Let's do an anova on the ols model fitting all features and the 2 feature set models

```{r}
anova(ols.log, ols.log5)

anova(ols.log, fit.step)
```

Both models are not significant worse than the model fit on all predictors


Let's do another anova on the feature set models and a small model fit only on the predictors they share

```{r}
vars.share <- c()
for (i in vars.step) {
  if (i %in% vars.vif) {
    vars.share <- c(vars.share, i)
  } else {
    print(i)
  }
}
vars.share

bdata.log.rm %>%
  select(c(vars.share, log_salary)) ->
bdata.share

ols.share <- lm(log_salary ~ career_PER + career_PTS + career_TRB + career_WS + 
    draft_round + draft_year + rank + G + TWOP_P + AST + TOV + PF + year, data = bdata.share)


anova(ols.share, fit.step)

anova(ols.share, ols.log5)
```

The step variables model has slight significant anova results, but not by much.

The vif variable models is not significantly better than the shared model

Let's do CV on the step, vif, and shared feature subsets to see which is the best at prediction

### Cross Validation

```{r}
library(boot)

ols.share <- glm(log_salary ~ ., data = bdata.share)

ols.vif <- glm(log_salary ~ ., data = bdata.vif)

ols.step <- glm(log_salary ~ ., data = bdata.step)

cv.share <- cv.glm(bdata.share, ols.share)

cv.vif <- cv.glm(bdata.vif, ols.vif)

cv.step <- cv.glm(bdata.step, ols.step)

c("Shared" = cv.share$delta[1], "VIF" = cv.vif$delta[1], "Step" = cv.step$delta[1])
```

The Shared data set actually had better cross validation results, though the set selected by VIF was quite close.

## Weighted Least Squares Regression

```{r}
# Shares Features
glm.share <- glm(log_salary ~ ., data= bdata.share)

glm.abs.res <- glm(abs(residuals(glm.share)) ~ fitted(glm.share))

wts.share <- 1/fitted(glm.abs.res)^2

bdata.share.wls <- bdata.share

wls.share <- glm(log_salary ~ ., data = bdata.share.wls, weights = wts.share)

bdata.share.wls$wts.share <- wts.share

cv.wls.share <- cv.glm(bdata.share.wls, wls.share)
```

```{r}
# VIF Features
glm.vif <- glm(log_salary ~ ., data= bdata.vif)

glm.abs.res <- glm(abs(residuals(glm.vif)) ~ fitted(glm.vif))

wts.vif <- 1/fitted(glm.abs.res)^2

bdata.vif.wls <- bdata.vif

wls.vif <- glm(log_salary ~ ., data = bdata.vif, weights = wts.vif)

bdata.vif.wls$wts.vif <- wts.vif

cv.wls.vif <- cv.glm(bdata.vif.wls, wls.vif)
```

```{r}
# Step Features

glm.step <- glm(log_salary ~ ., data= bdata.step)

glm.abs.res <- glm(abs(residuals(glm.step))~fitted(glm.step))

wts.step <- 1/fitted(glm.abs.res)^2

bdata.step.wls <- bdata.step

wls.step <- glm(log_salary ~ ., data = bdata.step, weights=wts.step)

bdata.step.wls$wts.step <- wts.step

cv.wls.step <- cv.glm(bdata.step.wls, wls.step)
```

```{r}
cbind("WLS Share" = cv.wls.share$delta, "OLS Share" = cv.share$delta,
      "WLS VIF" = cv.wls.vif$delta, "OLS VIF" = cv.vif$delta,
      "WLS Step" = cv.wls.step$delta, "OLS Step" = cv.step$delta)
```


Traditional OLS using the Shared Features is still producing the best CV results

## Regression Trees

```{r}
library(tree)

tree.share <- tree(log_salary ~ ., bdata.share)
```

# Conclusion

OLS with the Shared Feature set was the model with the best CV results

```{r}
summary(ols.share)
```

## Should We Remove the insignificant variables

```{r}
bdata.share %>%
  select(-TWOP_P, -career_FG3_P, -BLK) ->
bdata.share2

ols.share2 <- glm(log_salary ~ ., data = bdata.share2)

lm.share <- lm(log_salary ~ ., data = bdata.share)
lm.share2 <- lm(log_salary ~ ., data = bdata.share2)


anova(lm.share2, lm.share)

cv.ols.share2 <- cv.glm(bdata.share2, ols.share2)

cbind("Share" = cv.share$delta, "Share2" = cv.share$delta)
```

The OLS fit on the smaller subset of the shared features, with the insignificant predictors removed, has the exact same CV results as the OLS fit on the fully shared features.

Since the ANOVA test is insignificant, the simpler model is preferred.

# Final Model

```{r}
summary(ols.share2)
```



## Pieceise Model (Ignore this for now)

```{r}
fit.piecewise = lm(log_salary ~ . + I((year-2013) * (year>2013)), data = bdata.log)

summary(fit.piecewise)

plot(fit.piecewise, which = c(1, 2))
```



