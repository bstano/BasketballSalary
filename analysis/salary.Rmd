---
title: "Basketball Salary"
author: "Ben Stano, ADD NAMES"
date: "2/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Baseketballs Brooooo

```{r, message=FALSE}
library(tidyverse)
```

## Importing Data

```{r}
# players <- read_csv("../data/players.csv")
# stats.36 <- read_csv("../data/PlayerStatisticsPer36Min.csv")
# stats.100 <- read_csv("../data/PlayerStatisticsPer100Poss.csv")
# stats.g <- read_csv("../data/PlayerStatisticsPerGame.csv")
# # salary <- read_csv("../data/salaries_1985to2018.csv")
# salary2 <- read_csv("../data/nba-salaries.csv")
```

## Cleaning and Merging Data

```{r}
# stats.g <- stats.g %>%
#   mutate(name = str_replace(Player, "\\*", ""))
# stats.g <- stats.g %>%
#   mutate(key = str_c(name, as.character(year), sep = ""))
# salary2 <- salary2 %>%
#   mutate(key = str_c(name, as.character(season), sep = ""))
```

### Joining the Datasets

```{r}
# final.data <- players %>%
#   inner_join(salary2, by = "name") %>%
#   inner_join(stats.g, by = "key") %>%
#   select(-key) %>%
#   filter(year >= 2017)
# 
# write_csv(final.data, "../data/final_data.csv")

bdata.raw <- read_csv("../data/final_data.csv")
```

### Cleaning the Data

```{r}
bdata.raw <- read_csv("../data/final_data.csv")
# displaying null values in each column
bdata.raw %>%
  map_dbl(~sum(is.na(.))) %>%
  unname() ->
na.dbl

na.cols <- data.frame("variable" = colnames(bdata.raw),
                      "null.count" = na.dbl)

na.cols %>%
  filter(null.count > 0)

# parsing numbers from difficult columns
bdata.raw$career_FG3_P <- parse_number(as.character(bdata.raw$`career_FG3%`))
bdata.raw$career_FG_P <- parse_number(as.character(bdata.raw$`career_FG%`))
bdata.raw$career_FT_P <- parse_number(as.character(bdata.raw$`career_FT%`))
# cleaning height
heights <- str_split(bdata.raw$height, "\\-")
heights.df <- t(data.frame(heights))
heights.int <- as.integer(heights.df[,1]) * 12 + as.integer(heights.df[,2])
bdata.raw$height <- heights.int

bdata.raw %>%
  mutate(draft_pick = parse_number(draft_pick),
         draft_round = parse_number(draft_round),
         shoots_right = ifelse(str_detect(shoots, "Right"),1,0),
         weight = parse_number(weight),
         Pos = as.factor(Pos)) %>%
  rename(career_eFG_P = `career_eFG%`,
         FG_P = `FG%`,
         THREEP_P = `3P%`,
         THREEP = `3P`,
         THREEP_A = `3PA`,
         TWOP_P = `2P%`,
         TWOP = `2P`,
         TWOP_A = `2PA`,
         eFG_P = `eFG%`,
         FT_P = `FT%`) %>%
  select(-birthDate, -birthPlace, -college, -draft_team, -highSchool, -name.x,
         -position.x, -position.y, -team, -Player, -name.y, -season, -Tm,
         -`career_FG3%`, -`career_FG%`, -`career_FT%`, -shoots) %>%
  na.omit() ->
bdata.clean

bdata.clean %>%
  select(-`_id`) ->
bdata.model
```


## Variables Names

 - **salary**: player salary 

## Dimensionality Reduction

```{r}
ols.init <- lm(salary ~ ., data = bdata.model)

summary(ols.init)

plot(ols.init, which = 1)

plot(ols.init, which = 2)
```

```{r, message=FALSE}
# library(klaR)
library(car)

# cond.index(ols.init, bdata.model)

vif(ols.init)
```

## Transforming the Respsonse Variable

```{r}
bdata.model %>%
  mutate(log_salary = log(salary)) -> 
bdata.log

bdata.log$salary <- NULL
```

```{r}
ols.log <- lm(log_salary ~ ., data = bdata.log)

summary(ols.log)

plot(ols.log, which = c(1, 2))

# cond.index(ols.log, bdata.log)

vif(ols.log)
```
## Feature Selection

```{r}
vifs <- data.frame(vif(ols.log))

vifs %>%
  filter(GVIF > 1000) ->
vif.1000

drop.vars <- c(rownames(vif.1000))

bdata.log %>%
  select(-drop.vars) ->
bdata.log2
```

### Refitting

```{r}
ols.log2 <- lm(log_salary ~ ., data = bdata.log2)

summary(ols.log2)

plot(ols.log2, which = c(1, 2))

vif(ols.log2)
```
```{r}
vifs2 <- data.frame(vif(ols.log2))

vifs2 %>%
  filter(GVIF > 50) ->
vif.50

drop.vars <- c(rownames(vif.50))

bdata.log2 %>%
  select(-drop.vars) ->
bdata.log3
```

### Refitting Again

```{r}
ols.log3 <- lm(log_salary ~ ., data = bdata.log3)

summary(ols.log3)

plot(ols.log3, which = c(1, 2))

vif(ols.log3)
```

```{r}
vifs3 <- data.frame(vif(ols.log3))

vifs3 %>%
  filter(GVIF > 20) ->
vif.20

drop.vars <- c(rownames(vif.20))

bdata.log3 %>%
  select(-drop.vars) ->
bdata.log4
```

### Refitting AGAIN AGAIN

```{r}
ols.log4 <- lm(log_salary ~ ., data = bdata.log4)

summary(ols.log4)

plot(ols.log4, which = c(1, 2))

vif(ols.log4)
```

```{r}
vifs4 <- data.frame(vif(ols.log4))

vifs4 %>%
  filter(`vif.ols.log4.` > 12) ->
vif.12

drop.vars <- c(rownames(vif.12))

bdata.log4 %>%
  select(-drop.vars) ->
bdata.log5
```

### Final Fitting

```{r}
ols.log5 <- lm(log_salary ~ ., data = bdata.log5)

summary(ols.log5)

plot(ols.log5, which = c(1, 2))

vif(ols.log5)
```

## Feature Selection Use Stepwise Function

```{r}
fit.large <- lm(log_salary ~ ., data = bdata.log)

fit.small <- lm(log_salary ~ 1, data = bdata.log)

fit.step <- step(fit.large, fit.small)
```

### Two Feature Sets

```{r}
vars.vif <- names(vif(ols.log5))
bdata.vif <- bdata.log5

vars.step <- names(fit.step$coefficients)[-1]
bdata.log %>%
  select(c(vars.step, log_salary)) ->
bdata.step
```

## Validating Between the Two Feature Sets

Let's do an anova on the ols model fitting all features and the 2 feature set models

```{r}
anova(ols.log, ols.log5)

anova(ols.log, fit.step)
```

Both models are not significant worse than the model fit on all predictors


Let's do another anova on the feature set models and a small model fit only on the predictors they share

```{r}
vars.share <- c()
for (i in vars.step) {
  if (i %in% vars.vif) {
    vars.share <- c(vars.share, i)
  } else {
    print(i)
  }
}
vars.share

bdata.log %>%
  select(c(vars.share, log_salary)) ->
bdata.share

ols.share <- lm(log_salary ~ career_PER + career_PTS + career_TRB + career_WS + 
    draft_round + draft_year + rank + G + TWOP_P + AST + TOV + PF + year, data = bdata.share)


anova(ols.share, fit.step)

anova(ols.share, ols.log5)
```

The step variables model has slight significant anova results, but not by much.

The vif variable models is not significantly better than the shared model

Let's do CV on the step, vif, and shared feature subsets to see which is the best at prediction

### Cross Validation

```{r}

```

## Pieceise Model (Ignore this for now)

```{r}
fit.piecewise = lm(log_salary ~ . + I((year-2013) * (year>2013)), data = bdata.log)

summary(fit.piecewise)

plot(fit.piecewise, which = c(1, 2))
```


### Ridge/LASSO

### Feature Engineering

## Modeling

Possible Models:

OLS Regression

WLS Regression

GLM Regression

Regression Trees

Splines


